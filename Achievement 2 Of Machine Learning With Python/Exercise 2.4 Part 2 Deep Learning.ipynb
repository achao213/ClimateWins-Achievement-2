{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db8e7e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from numpy import unique\n",
    "from numpy import reshape\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, Dense, BatchNormalization, Flatten, MaxPooling1D, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24ef7610",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_path = 'C:/Users/kuohe/ClimateWins/02 Data/Dataset-weather-prediction-dataset-processed (2).csv'\n",
    "pleasant_data_path = 'C:/Users/kuohe/ClimateWins/02 Data/pleasant weather.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17cc0535",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = pd.read_csv(weather_data_path)\n",
    "pleasant_data = pd.read_csv(pleasant_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "226b1fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       DATE  MONTH  BASEL_cloud_cover  BASEL_wind_speed  BASEL_humidity  \\\n",
      "0  19600101      1                  7               2.1            0.85   \n",
      "1  19600102      1                  6               2.1            0.84   \n",
      "2  19600103      1                  8               2.1            0.90   \n",
      "3  19600104      1                  3               2.1            0.92   \n",
      "4  19600105      1                  6               2.1            0.95   \n",
      "\n",
      "   BASEL_pressure  BASEL_global_radiation  BASEL_precipitation  \\\n",
      "0           1.018                    0.32                 0.09   \n",
      "1           1.018                    0.36                 1.05   \n",
      "2           1.018                    0.18                 0.30   \n",
      "3           1.018                    0.58                 0.00   \n",
      "4           1.018                    0.65                 0.14   \n",
      "\n",
      "   BASEL_snow_depth  BASEL_sunshine  ...  VALENTIA_cloud_cover  \\\n",
      "0                 0             0.7  ...                     5   \n",
      "1                 0             1.1  ...                     7   \n",
      "2                 0             0.0  ...                     7   \n",
      "3                 0             4.1  ...                     7   \n",
      "4                 0             5.4  ...                     3   \n",
      "\n",
      "   VALENTIA_humidity  VALENTIA_pressure  VALENTIA_global_radiation  \\\n",
      "0               0.88             1.0003                       0.45   \n",
      "1               0.91             1.0007                       0.25   \n",
      "2               0.91             1.0096                       0.17   \n",
      "3               0.86             1.0184                       0.13   \n",
      "4               0.80             1.0328                       0.46   \n",
      "\n",
      "   VALENTIA_precipitation  VALENTIA_snow_depth  VALENTIA_sunshine  \\\n",
      "0                    0.34                    0                4.7   \n",
      "1                    0.84                    0                0.7   \n",
      "2                    0.08                    0                0.1   \n",
      "3                    0.98                    0                0.0   \n",
      "4                    0.00                    0                5.7   \n",
      "\n",
      "   VALENTIA_temp_mean  VALENTIA_temp_min  VALENTIA_temp_max  \n",
      "0                 8.5                6.0               10.9  \n",
      "1                 8.9                5.6               12.1  \n",
      "2                10.5                8.1               12.9  \n",
      "3                 7.4                7.3               10.6  \n",
      "4                 5.7                3.0                8.4  \n",
      "\n",
      "[5 rows x 170 columns]\n",
      "       DATE  BASEL_pleasant_weather  BELGRADE_pleasant_weather  \\\n",
      "0  19600101                       0                          0   \n",
      "1  19600102                       0                          0   \n",
      "2  19600103                       0                          0   \n",
      "3  19600104                       0                          0   \n",
      "4  19600105                       0                          0   \n",
      "\n",
      "   BUDAPEST_pleasant_weather  DEBILT_pleasant_weather  \\\n",
      "0                          0                        0   \n",
      "1                          0                        0   \n",
      "2                          0                        0   \n",
      "3                          0                        0   \n",
      "4                          0                        0   \n",
      "\n",
      "   DUSSELDORF_pleasant_weather  HEATHROW_pleasant_weather  \\\n",
      "0                            0                          0   \n",
      "1                            0                          0   \n",
      "2                            0                          0   \n",
      "3                            0                          0   \n",
      "4                            0                          0   \n",
      "\n",
      "   KASSEL_pleasant_weather  LJUBLJANA_pleasant_weather  \\\n",
      "0                        0                           0   \n",
      "1                        0                           0   \n",
      "2                        0                           0   \n",
      "3                        0                           0   \n",
      "4                        0                           0   \n",
      "\n",
      "   MAASTRICHT_pleasant_weather  MADRID_pleasant_weather  \\\n",
      "0                            0                        0   \n",
      "1                            0                        0   \n",
      "2                            0                        0   \n",
      "3                            0                        0   \n",
      "4                            0                        0   \n",
      "\n",
      "   MUNCHENB_pleasant_weather  OSLO_pleasant_weather  \\\n",
      "0                          0                      0   \n",
      "1                          0                      0   \n",
      "2                          0                      0   \n",
      "3                          0                      0   \n",
      "4                          0                      0   \n",
      "\n",
      "   SONNBLICK_pleasant_weather  STOCKHOLM_pleasant_weather  \\\n",
      "0                           0                           0   \n",
      "1                           0                           0   \n",
      "2                           0                           0   \n",
      "3                           0                           0   \n",
      "4                           0                           0   \n",
      "\n",
      "   VALENTIA_pleasant_weather  \n",
      "0                          0  \n",
      "1                          0  \n",
      "2                          0  \n",
      "3                          0  \n",
      "4                          0  \n"
     ]
    }
   ],
   "source": [
    "print(weather_data.head())\n",
    "print(pleasant_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ab7d1d",
   "metadata": {},
   "source": [
    "I would choose RNN because LSTM units in recurrent neural networks (RNNs) can capture long-term dependencies and handle sequences well, they are perfect for weather data analysis. They are especially useful for long-term weather pattern prediction because they are resilient to gaps and irregularities in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "355b1066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_rnn_model(input_shape):\n",
    "#     model = Sequential()\n",
    "    \n",
    "#     model.add(LSTM(units=50, return_sequences=True, input_shape=input_shape))\n",
    "#     model.add(Dropout(0.2))  \n",
    "    \n",
    "#     model.add(LSTM(units=50))\n",
    "#     model.add(Dropout(0.2))\n",
    "    \n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "#     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "511b4804",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data.drop(columns=['DATE', 'MONTH'], inplace=True)\n",
    "\n",
    "pleasant_data.drop(columns=['DATE'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e467f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   BASEL_cloud_cover  BASEL_wind_speed  BASEL_humidity  BASEL_pressure  \\\n",
      "0                  7               2.1            0.85           1.018   \n",
      "1                  6               2.1            0.84           1.018   \n",
      "2                  8               2.1            0.90           1.018   \n",
      "3                  3               2.1            0.92           1.018   \n",
      "4                  6               2.1            0.95           1.018   \n",
      "\n",
      "   BASEL_global_radiation  BASEL_precipitation  BASEL_snow_depth  \\\n",
      "0                    0.32                 0.09                 0   \n",
      "1                    0.36                 1.05                 0   \n",
      "2                    0.18                 0.30                 0   \n",
      "3                    0.58                 0.00                 0   \n",
      "4                    0.65                 0.14                 0   \n",
      "\n",
      "   BASEL_sunshine  BASEL_temp_mean  BASEL_temp_min  ...  VALENTIA_cloud_cover  \\\n",
      "0             0.7              6.5             0.8  ...                     5   \n",
      "1             1.1              6.1             3.3  ...                     7   \n",
      "2             0.0              8.5             5.1  ...                     7   \n",
      "3             4.1              6.3             3.8  ...                     7   \n",
      "4             5.4              3.0            -0.7  ...                     3   \n",
      "\n",
      "   VALENTIA_humidity  VALENTIA_pressure  VALENTIA_global_radiation  \\\n",
      "0               0.88             1.0003                       0.45   \n",
      "1               0.91             1.0007                       0.25   \n",
      "2               0.91             1.0096                       0.17   \n",
      "3               0.86             1.0184                       0.13   \n",
      "4               0.80             1.0328                       0.46   \n",
      "\n",
      "   VALENTIA_precipitation  VALENTIA_snow_depth  VALENTIA_sunshine  \\\n",
      "0                    0.34                    0                4.7   \n",
      "1                    0.84                    0                0.7   \n",
      "2                    0.08                    0                0.1   \n",
      "3                    0.98                    0                0.0   \n",
      "4                    0.00                    0                5.7   \n",
      "\n",
      "   VALENTIA_temp_mean  VALENTIA_temp_min  VALENTIA_temp_max  \n",
      "0                 8.5                6.0               10.9  \n",
      "1                 8.9                5.6               12.1  \n",
      "2                10.5                8.1               12.9  \n",
      "3                 7.4                7.3               10.6  \n",
      "4                 5.7                3.0                8.4  \n",
      "\n",
      "[5 rows x 168 columns]\n"
     ]
    }
   ],
   "source": [
    "print(weather_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8343edea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   BASEL_pleasant_weather  BELGRADE_pleasant_weather  \\\n",
      "0                       0                          0   \n",
      "1                       0                          0   \n",
      "2                       0                          0   \n",
      "3                       0                          0   \n",
      "4                       0                          0   \n",
      "\n",
      "   BUDAPEST_pleasant_weather  DEBILT_pleasant_weather  \\\n",
      "0                          0                        0   \n",
      "1                          0                        0   \n",
      "2                          0                        0   \n",
      "3                          0                        0   \n",
      "4                          0                        0   \n",
      "\n",
      "   DUSSELDORF_pleasant_weather  HEATHROW_pleasant_weather  \\\n",
      "0                            0                          0   \n",
      "1                            0                          0   \n",
      "2                            0                          0   \n",
      "3                            0                          0   \n",
      "4                            0                          0   \n",
      "\n",
      "   KASSEL_pleasant_weather  LJUBLJANA_pleasant_weather  \\\n",
      "0                        0                           0   \n",
      "1                        0                           0   \n",
      "2                        0                           0   \n",
      "3                        0                           0   \n",
      "4                        0                           0   \n",
      "\n",
      "   MAASTRICHT_pleasant_weather  MADRID_pleasant_weather  \\\n",
      "0                            0                        0   \n",
      "1                            0                        0   \n",
      "2                            0                        0   \n",
      "3                            0                        0   \n",
      "4                            0                        0   \n",
      "\n",
      "   MUNCHENB_pleasant_weather  OSLO_pleasant_weather  \\\n",
      "0                          0                      0   \n",
      "1                          0                      0   \n",
      "2                          0                      0   \n",
      "3                          0                      0   \n",
      "4                          0                      0   \n",
      "\n",
      "   SONNBLICK_pleasant_weather  STOCKHOLM_pleasant_weather  \\\n",
      "0                           0                           0   \n",
      "1                           0                           0   \n",
      "2                           0                           0   \n",
      "3                           0                           0   \n",
      "4                           0                           0   \n",
      "\n",
      "   VALENTIA_pleasant_weather  \n",
      "0                          0  \n",
      "1                          0  \n",
      "2                          0  \n",
      "3                          0  \n",
      "4                          0  \n"
     ]
    }
   ],
   "source": [
    "print(pleasant_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8c61dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad2ccfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pleasant_columns = list(pleasant_data.columns)\n",
    "station_names = [x.split(\"_\")[0] for x in pleasant_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "971a93a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(station_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7dd4571",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = []\n",
    "for col in station_names:\n",
    "    for weather_col in weather_data.columns:\n",
    "        if col in weather_col:\n",
    "            cols_to_keep.append(weather_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d6dd3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cols_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a77e2806",
   "metadata": {},
   "outputs": [],
   "source": [
    "basel_cols = [col for col in cols_to_keep if 'BASEL' in col]\n",
    "belgrade_cols = [col for col in cols_to_keep if 'BELGRADE' in col]\n",
    "stockholm_cols = [col for col in cols_to_keep if 'STOCKHOLM' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df5211f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BASEL_cloud_cover',\n",
       " 'BASEL_wind_speed',\n",
       " 'BASEL_humidity',\n",
       " 'BASEL_pressure',\n",
       " 'BASEL_global_radiation',\n",
       " 'BASEL_precipitation',\n",
       " 'BASEL_snow_depth',\n",
       " 'BASEL_sunshine',\n",
       " 'BASEL_temp_mean',\n",
       " 'BASEL_temp_min',\n",
       " 'BASEL_temp_max']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basel_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0c6ae1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BELGRADE_cloud_cover',\n",
       " 'BELGRADE_humidity',\n",
       " 'BELGRADE_pressure',\n",
       " 'BELGRADE_global_radiation',\n",
       " 'BELGRADE_precipitation',\n",
       " 'BELGRADE_sunshine',\n",
       " 'BELGRADE_temp_mean',\n",
       " 'BELGRADE_temp_min',\n",
       " 'BELGRADE_temp_max']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "belgrade_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1db84f6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STOCKHOLM_cloud_cover',\n",
       " 'STOCKHOLM_pressure',\n",
       " 'STOCKHOLM_global_radiation',\n",
       " 'STOCKHOLM_precipitation',\n",
       " 'STOCKHOLM_sunshine',\n",
       " 'STOCKHOLM_temp_mean',\n",
       " 'STOCKHOLM_temp_min',\n",
       " 'STOCKHOLM_temp_max']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stockholm_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "375e530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_attributes=[col.replace('BELGRADE_', '') for col in belgrade_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34907f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cloud_cover',\n",
       " 'humidity',\n",
       " 'pressure',\n",
       " 'global_radiation',\n",
       " 'precipitation',\n",
       " 'sunshine',\n",
       " 'temp_mean',\n",
       " 'temp_min',\n",
       " 'temp_max']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe888107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASEL_wind_speed\n",
      "BASEL_snow_depth\n",
      "DEBILT_wind_speed\n",
      "DUSSELDORF_wind_speed\n",
      "DUSSELDORF_snow_depth\n",
      "HEATHROW_snow_depth\n",
      "KASSEL_wind_speed\n",
      "LJUBLJANA_wind_speed\n",
      "MAASTRICHT_wind_speed\n",
      "MADRID_wind_speed\n",
      "MUNCHENB_snow_depth\n",
      "OSLO_wind_speed\n",
      "OSLO_snow_depth\n",
      "SONNBLICK_wind_speed\n",
      "VALENTIA_snow_depth\n"
     ]
    }
   ],
   "source": [
    "new_cols_to_keep = []\n",
    "for col in cols_to_keep:\n",
    "    if 'wind_speed' in col or 'snow_depth' in col:\n",
    "        print(col)\n",
    "        continue\n",
    "    else:\n",
    "        new_cols_to_keep.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31e3c7db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_cols_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "817d7fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_dic = {station:0 for station in station_names}\n",
    "for station in station_names:\n",
    "    for col in cols_to_keep:\n",
    "        if station in col:\n",
    "            station_dic[station]+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2eb7ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BASEL': 11,\n",
       " 'BELGRADE': 9,\n",
       " 'BUDAPEST': 9,\n",
       " 'DEBILT': 10,\n",
       " 'DUSSELDORF': 11,\n",
       " 'HEATHROW': 10,\n",
       " 'KASSEL': 9,\n",
       " 'LJUBLJANA': 10,\n",
       " 'MAASTRICHT': 10,\n",
       " 'MADRID': 10,\n",
       " 'MUNCHENB': 9,\n",
       " 'OSLO': 11,\n",
       " 'SONNBLICK': 10,\n",
       " 'STOCKHOLM': 8,\n",
       " 'VALENTIA': 10}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae96537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_dic = {attribute:0 for attribute in weather_attributes}\n",
    "for attribute in weather_attributes:\n",
    "    for col in cols_to_keep:\n",
    "        if attribute in col:\n",
    "            attribute_dic[attribute]+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1e75170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cloud_cover': 14,\n",
       " 'humidity': 14,\n",
       " 'pressure': 14,\n",
       " 'global_radiation': 15,\n",
       " 'precipitation': 15,\n",
       " 'sunshine': 15,\n",
       " 'temp_mean': 15,\n",
       " 'temp_min': 15,\n",
       " 'temp_max': 15}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribute_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c24809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ljubljana_cols = [col for col in cols_to_keep if 'LJUBLJANA' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f60a11bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LJUBLJANA_cloud_cover',\n",
       " 'LJUBLJANA_wind_speed',\n",
       " 'LJUBLJANA_humidity',\n",
       " 'LJUBLJANA_pressure',\n",
       " 'LJUBLJANA_global_radiation',\n",
       " 'LJUBLJANA_precipitation',\n",
       " 'LJUBLJANA_sunshine',\n",
       " 'LJUBLJANA_temp_mean',\n",
       " 'LJUBLJANA_temp_min',\n",
       " 'LJUBLJANA_temp_max']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ljubljana_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "724e8ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kassel_cols = [col for col in cols_to_keep if 'KASSEL' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20d54531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KASSEL_wind_speed',\n",
       " 'KASSEL_humidity',\n",
       " 'KASSEL_pressure',\n",
       " 'KASSEL_global_radiation',\n",
       " 'KASSEL_precipitation',\n",
       " 'KASSEL_sunshine',\n",
       " 'KASSEL_temp_mean',\n",
       " 'KASSEL_temp_min',\n",
       " 'KASSEL_temp_max']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kassel_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2278c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = weather_data[new_cols_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3953941",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data['KASSEL_cloud_cover']=weather_data['LJUBLJANA_cloud_cover']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f991397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "munchen_cols = [col for col in cols_to_keep if 'MUNCHEN' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b49b2eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MUNCHENB_cloud_cover',\n",
       " 'MUNCHENB_humidity',\n",
       " 'MUNCHENB_global_radiation',\n",
       " 'MUNCHENB_precipitation',\n",
       " 'MUNCHENB_snow_depth',\n",
       " 'MUNCHENB_sunshine',\n",
       " 'MUNCHENB_temp_mean',\n",
       " 'MUNCHENB_temp_min',\n",
       " 'MUNCHENB_temp_max']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "munchen_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9400e584",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data['MUNCHENB_pressure']=weather_data['SONNBLICK_pressure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0e69750",
   "metadata": {},
   "outputs": [],
   "source": [
    "stockholm_cols = [col for col in cols_to_keep if 'STOCKHOLM' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2151bbfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STOCKHOLM_cloud_cover',\n",
       " 'STOCKHOLM_pressure',\n",
       " 'STOCKHOLM_global_radiation',\n",
       " 'STOCKHOLM_precipitation',\n",
       " 'STOCKHOLM_sunshine',\n",
       " 'STOCKHOLM_temp_mean',\n",
       " 'STOCKHOLM_temp_min',\n",
       " 'STOCKHOLM_temp_max']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stockholm_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e282ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data['STOCKHOLM_humidity']=weather_data['OSLO_humidity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03690f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 135)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "653a13d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully saved to C:\\Users\\kuohe\\ClimateWins\\02 Data\\cleaned_weather_data.csv\n"
     ]
    }
   ],
   "source": [
    "save_path = r'C:\\Users\\kuohe\\ClimateWins\\02 Data\\cleaned_weather_data.csv'\n",
    "weather_data.to_csv(save_path, index=False)\n",
    "print(f\"Data has been successfully saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b701a534",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_weather_data = 'C:/Users/kuohe/ClimateWins/02 Data/cleaned_weather_data.csv'\n",
    "cleaned_weather_data = pd.read_csv(cleaned_weather_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8446e091",
   "metadata": {},
   "outputs": [],
   "source": [
    "pleasant_weather_data_path = 'C:/Users/kuohe/ClimateWins/02 Data/pleasant weather.csv'\n",
    "pleasant_weather_data = pd.read_csv(pleasant_weather_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9f40eae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pleasant_weather_data.drop(columns=['DATE'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a00adabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleaned_weather_data.values.reshape(-1,15,9)\n",
    "y = pleasant_weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17c67548",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4867d9f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e080de0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kuohe\\anaconda2\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,900</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,050</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">350</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,265</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │         \u001b[38;5;34m1,900\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │         \u001b[38;5;34m5,050\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m50\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m350\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │         \u001b[38;5;34m5,265\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,215</span> (47.71 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,215\u001b[0m (47.71 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,215</span> (47.71 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,215\u001b[0m (47.71 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(100, kernel_size=2, activation='relu', input_shape=(15,9)))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(15, activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer = keras.optimizers.Adam(learning_rate=0.0000001), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "490c5570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0559 - loss: 19.8574\n",
      "Epoch 2/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0607 - loss: 18.9238\n",
      "Epoch 3/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0667 - loss: 18.7365\n",
      "Epoch 4/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0749 - loss: 18.0676\n",
      "Epoch 5/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0836 - loss: 17.8838\n",
      "Epoch 6/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0846 - loss: 17.6904\n",
      "Epoch 7/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0926 - loss: 17.0678\n",
      "Epoch 8/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0995 - loss: 16.6160\n",
      "Epoch 9/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1073 - loss: 16.6154\n",
      "Epoch 10/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1103 - loss: 16.1264\n",
      "Epoch 11/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1191 - loss: 16.3047\n",
      "Epoch 12/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1221 - loss: 15.8307\n",
      "Epoch 13/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1244 - loss: 15.8566\n",
      "Epoch 14/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1291 - loss: 15.6561\n",
      "Epoch 15/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1281 - loss: 15.6827\n",
      "Epoch 16/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1395 - loss: 15.1521\n",
      "Epoch 17/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1390 - loss: 15.2087\n",
      "Epoch 18/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1422 - loss: 15.0512\n",
      "Epoch 19/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1438 - loss: 15.0734\n",
      "Epoch 20/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1467 - loss: 15.2842\n",
      "Epoch 21/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1504 - loss: 14.7843\n",
      "Epoch 22/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1527 - loss: 14.7528\n",
      "Epoch 23/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1553 - loss: 14.9874\n",
      "Epoch 24/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1613 - loss: 14.6750\n",
      "Epoch 25/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1641 - loss: 14.6538\n",
      "Epoch 26/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1585 - loss: 14.6654\n",
      "Epoch 27/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1582 - loss: 14.5646\n",
      "Epoch 28/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1619 - loss: 14.8366\n",
      "Epoch 29/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1640 - loss: 14.6473\n",
      "Epoch 30/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1649 - loss: 14.6720\n",
      "Epoch 31/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1711 - loss: 14.5333\n",
      "Epoch 32/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1774 - loss: 14.3676\n",
      "Epoch 33/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1671 - loss: 14.7136\n",
      "Epoch 34/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1738 - loss: 14.5813\n",
      "Epoch 35/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1764 - loss: 14.6262\n",
      "Epoch 36/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1748 - loss: 14.9124\n",
      "Epoch 37/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1754 - loss: 14.4660\n",
      "Epoch 38/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1757 - loss: 14.7278\n",
      "Epoch 39/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1807 - loss: 14.6556\n",
      "Epoch 40/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1785 - loss: 14.6614\n",
      "Epoch 41/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1831 - loss: 14.6108\n",
      "Epoch 42/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1841 - loss: 14.9348\n",
      "Epoch 43/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1778 - loss: 14.4032\n",
      "Epoch 44/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1787 - loss: 14.9121\n",
      "Epoch 45/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1820 - loss: 15.2493\n",
      "Epoch 46/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1818 - loss: 14.7887\n",
      "Epoch 47/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1867 - loss: 14.9259\n",
      "Epoch 48/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1869 - loss: 15.0253\n",
      "Epoch 49/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1857 - loss: 15.2574\n",
      "Epoch 50/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1852 - loss: 14.8572\n",
      "Epoch 51/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1911 - loss: 15.0659\n",
      "Epoch 52/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1877 - loss: 15.1127\n",
      "Epoch 53/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1862 - loss: 14.9401\n",
      "Epoch 54/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1890 - loss: 15.0829\n",
      "Epoch 55/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1863 - loss: 15.0730\n",
      "Epoch 56/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1895 - loss: 15.2347\n",
      "Epoch 57/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1901 - loss: 15.1533\n",
      "Epoch 58/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1827 - loss: 15.1379\n",
      "Epoch 59/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1852 - loss: 15.1889\n",
      "Epoch 60/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1853 - loss: 15.3744\n",
      "Epoch 61/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1891 - loss: 15.2195\n",
      "Epoch 62/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1859 - loss: 15.6020\n",
      "Epoch 63/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1892 - loss: 15.4073\n",
      "Epoch 64/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1864 - loss: 15.3506\n",
      "Epoch 65/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1919 - loss: 15.4871\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1885 - loss: 15.7173\n",
      "Epoch 67/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1835 - loss: 15.4477\n",
      "Epoch 68/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1866 - loss: 15.7192\n",
      "Epoch 69/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1871 - loss: 15.6384\n",
      "Epoch 70/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1856 - loss: 15.9321\n",
      "Epoch 71/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1873 - loss: 15.9858\n",
      "Epoch 72/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1903 - loss: 15.8484\n",
      "Epoch 73/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1812 - loss: 16.0505\n",
      "Epoch 74/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1818 - loss: 16.1384\n",
      "Epoch 75/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1813 - loss: 15.9451\n",
      "Epoch 76/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1856 - loss: 16.0404\n",
      "Epoch 77/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1814 - loss: 16.2150\n",
      "Epoch 78/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1865 - loss: 16.4367\n",
      "Epoch 79/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1893 - loss: 16.2836\n",
      "Epoch 80/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1876 - loss: 16.2726\n",
      "Epoch 81/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1849 - loss: 16.2672\n",
      "Epoch 82/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1871 - loss: 16.2302\n",
      "Epoch 83/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1860 - loss: 16.5572\n",
      "Epoch 84/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1839 - loss: 16.5860\n",
      "Epoch 85/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1837 - loss: 16.4837\n",
      "Epoch 86/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1851 - loss: 16.4972\n",
      "Epoch 87/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1836 - loss: 16.6199\n",
      "Epoch 88/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1820 - loss: 16.7305\n",
      "Epoch 89/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1854 - loss: 17.0560\n",
      "Epoch 90/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1819 - loss: 16.7960\n",
      "Epoch 91/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1815 - loss: 16.7416\n",
      "Epoch 92/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1825 - loss: 16.6466\n",
      "Epoch 93/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1800 - loss: 16.6225\n",
      "Epoch 94/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1769 - loss: 16.9669\n",
      "Epoch 95/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1829 - loss: 16.8277\n",
      "Epoch 96/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1842 - loss: 16.7724\n",
      "Epoch 97/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1805 - loss: 16.9568\n",
      "Epoch 98/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1832 - loss: 16.6297\n",
      "Epoch 99/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1820 - loss: 16.8239\n",
      "Epoch 100/100\n",
      "\u001b[1m1148/1148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1856 - loss: 17.0805\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1774 - loss: 17.2929\n",
      "Loss: 17.093053817749023 Accuracy 0.18033769726753235\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train,batch_size=16, epochs=100,verbose=1)\n",
    "acc = model.evaluate(X_train,y_train)\n",
    "print('Loss:', acc[0], 'Accuracy', acc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2c2dec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_rnn_model(input_shape, n_classes):\n",
    "#     model = Sequential([\n",
    "#         LSTM(units=300, return_sequences=False, input_shape=input_shape),\n",
    "#         LSTM(units=200, return_sequences=False),\n",
    "#         Dropout(0.2),\n",
    "#         Dense(units=100, activation='sigmoid'),\n",
    "#         Dropout(0.2),\n",
    "#         Dense(units=n_classes, activation='softmax')\n",
    "#     ])\n",
    "#     model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "933e323b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d5264393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.14      0.23      2931\n",
      "           1       0.27      0.47      0.34       907\n",
      "           2       0.00      0.00      0.00       174\n",
      "           3       0.00      0.00      0.00        53\n",
      "           4       0.00      0.00      0.00        28\n",
      "           5       0.00      0.00      0.00        80\n",
      "           6       0.00      0.00      0.00        12\n",
      "           7       0.01      0.08      0.02        53\n",
      "           8       0.00      0.00      0.00         6\n",
      "           9       0.09      0.35      0.14       336\n",
      "          10       0.00      0.00      0.00         4\n",
      "          11       0.00      0.00      0.00         2\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.21      4590\n",
      "   macro avg       0.08      0.07      0.05      4590\n",
      "weighted avg       0.57      0.21      0.23      4590\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kuohe\\anaconda2\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kuohe\\anaconda2\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kuohe\\anaconda2\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test = np.argmax(y_test, axis=1) if y_test.ndim > 1 else y_test\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)  # Convert probabilities to class labels\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6d0b7b",
   "metadata": {},
   "source": [
    "# EXERICSE 2.4 Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4e05af01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from math import floor\n",
    "import operator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Dense, Dropout, BatchNormalization, Flatten, MaxPooling1D, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings for pandas\n",
    "pd.set_option(\"display.max_columns\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9d3fd8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_weather_data_path = 'C:/Users/kuohe/ClimateWins/02 Data/cleaned_weather_data.csv'\n",
    "pleasant_weather_data_path = 'C:/Users/kuohe/ClimateWins/02 Data/pleasant weather.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "df2af9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_weather_data = pd.read_csv(cleaned_weather_data_path)\n",
    "pleasant_weather_data = pd.read_csv(pleasant_weather_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "03c19a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleaned_weather_data.values.reshape(-1, 15, 9)\n",
    "y = pleasant_weather_data.drop('DATE', axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0aef959e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (22950, 15, 9)\n",
      "y shape: (22950,)\n"
     ]
    }
   ],
   "source": [
    "y = np.argmax(y, axis=1)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "936d3ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d4b969c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | activa... | batch_... |  dropout  | dropou... |  epochs   |  kernel   |  layers1  |  layers2  | learni... |  neurons  | normal... | optimizer |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 1/16\n",
      "1/1 - 2s - 2s/step - accuracy: 0.4500 - loss: 0.6997\n",
      "Epoch 2/16\n",
      "1/1 - 0s - 28ms/step - accuracy: 0.5500 - loss: 0.6919\n",
      "Epoch 3/16\n",
      "1/1 - 0s - 30ms/step - accuracy: 0.5500 - loss: 0.6913\n",
      "Epoch 4/16\n",
      "1/1 - 0s - 34ms/step - accuracy: 0.5500 - loss: 0.6907\n",
      "Epoch 5/16\n",
      "1/1 - 0s - 28ms/step - accuracy: 0.5500 - loss: 0.6903\n",
      "Epoch 6/16\n",
      "1/1 - 0s - 28ms/step - accuracy: 0.5500 - loss: 0.6899\n",
      "Epoch 7/16\n",
      "1/1 - 0s - 28ms/step - accuracy: 0.5500 - loss: 0.6896\n",
      "Epoch 8/16\n",
      "1/1 - 0s - 29ms/step - accuracy: 0.5500 - loss: 0.6893\n",
      "Epoch 9/16\n",
      "1/1 - 0s - 29ms/step - accuracy: 0.5500 - loss: 0.6891\n",
      "Epoch 10/16\n",
      "1/1 - 0s - 27ms/step - accuracy: 0.5500 - loss: 0.6890\n",
      "Epoch 11/16\n",
      "1/1 - 0s - 28ms/step - accuracy: 0.5500 - loss: 0.6888\n",
      "Epoch 12/16\n",
      "1/1 - 0s - 25ms/step - accuracy: 0.5500 - loss: 0.6887\n",
      "Epoch 13/16\n",
      "1/1 - 0s - 28ms/step - accuracy: 0.5500 - loss: 0.6886\n",
      "Epoch 14/16\n",
      "1/1 - 0s - 27ms/step - accuracy: 0.5500 - loss: 0.6885\n",
      "Epoch 15/16\n",
      "1/1 - 0s - 27ms/step - accuracy: 0.5500 - loss: 0.6885\n",
      "Epoch 16/16\n",
      "1/1 - 0s - 27ms/step - accuracy: 0.5500 - loss: 0.6884\n",
      "1/1 - 0s - 63ms/step\n",
      "Epoch 1/16\n",
      "Epoch 1/16\n",
      "Epoch 1/16\n",
      "Epoch 1/16\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m2.996    \u001b[0m | \u001b[0m95.56    \u001b[0m | \u001b[0m0.732    \u001b[0m | \u001b[0m0.3395   \u001b[0m | \u001b[0m16.24    \u001b[0m | \u001b[0m1.624    \u001b[0m | \u001b[0m1.232    \u001b[0m | \u001b[0m4.465    \u001b[0m | \u001b[0m0.06015  \u001b[0m | \u001b[0m73.73    \u001b[0m | \u001b[0m0.02058  \u001b[0m | \u001b[0m6.789    \u001b[0m |\n",
      "Epoch 1/22\n",
      "3/3 - 1s - 499ms/step - accuracy: 0.4500 - loss: nan\n",
      "Epoch 2/22\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.4500 - loss: nan\n",
      "Epoch 3/22\n",
      "3/3 - 0s - 12ms/step - accuracy: 0.4500 - loss: nan\n",
      "Epoch 4/22\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.4500 - loss: nan\n",
      "Epoch 5/22\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.4500 - loss: nan\n",
      "Epoch 6/22\n",
      "3/3 - 0s - 10ms/step - accuracy: 0.4500 - loss: nan\n",
      "Epoch 7/22\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.4500 - loss: nan\n",
      "Epoch 8/22\n",
      "3/3 - 0s - 10ms/step - accuracy: 0.4500 - loss: nan\n",
      "Epoch 9/22\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.4500 - loss: nan\n",
      "Epoch 10/22\n",
      "3/3 - 0s - 12ms/step - accuracy: 0.4500 - loss: nan\n",
      "Epoch 11/22\n",
      "3/3 - 0s - 8ms/step - accuracy: 0.4500 - loss: nan\n",
      "Epoch 12/22\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.4500 - loss: nan\n",
      "Epoch 13/22\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.4500 - loss: nan\n",
      "Epoch 14/22\n",
      "3/3 - 0s - 10ms/step - accuracy: 0.4500 - loss: nan\n",
      "Epoch 15/22\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.4500 - loss: nan\n",
      "Epoch 16/22\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.4500 - loss: nan\n",
      "Epoch 17/22\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.4500 - loss: nan\n",
      "Epoch 18/22\n",
      "3/3 - 0s - 10ms/step - accuracy: 0.4500 - loss: nan\n",
      "Epoch 19/22\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.4500 - loss: nan\n",
      "Epoch 20/22\n",
      "3/3 - 0s - 10ms/step - accuracy: 0.4500 - loss: nan\n",
      "Epoch 21/22\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.4500 - loss: nan\n",
      "Epoch 22/22\n",
      "3/3 - 0s - 9ms/step - accuracy: 0.4500 - loss: nan\n",
      "1/1 - 0s - 66ms/step\n",
      "Epoch 1/22\n",
      "Epoch 1/22\n",
      "Epoch 1/22\n",
      "Epoch 1/22\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m6.66     \u001b[0m | \u001b[0m29.11    \u001b[0m | \u001b[0m0.1818   \u001b[0m | \u001b[0m0.1734   \u001b[0m | \u001b[0m22.17    \u001b[0m | \u001b[0m3.099    \u001b[0m | \u001b[0m2.728    \u001b[0m | \u001b[0m2.165    \u001b[0m | \u001b[0m0.06122  \u001b[0m | \u001b[0m22.55    \u001b[0m | \u001b[0m0.2921   \u001b[0m | \u001b[0m2.565    \u001b[0m |\n",
      "Epoch 1/34\n",
      "1/1 - 2s - 2s/step - accuracy: 0.5750 - loss: 0.7314\n",
      "Epoch 2/34\n",
      "1/1 - 0s - 31ms/step - accuracy: 0.4875 - loss: 0.8328\n",
      "Epoch 3/34\n",
      "1/1 - 0s - 35ms/step - accuracy: 0.5625 - loss: 1.0287\n",
      "Epoch 4/34\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.5125 - loss: 0.8163\n",
      "Epoch 5/34\n",
      "1/1 - 0s - 22ms/step - accuracy: 0.5875 - loss: 0.8952\n",
      "Epoch 6/34\n",
      "1/1 - 0s - 34ms/step - accuracy: 0.4750 - loss: 0.9277\n",
      "Epoch 7/34\n",
      "1/1 - 0s - 32ms/step - accuracy: 0.5875 - loss: 0.8176\n",
      "Epoch 8/34\n",
      "1/1 - 0s - 30ms/step - accuracy: 0.6250 - loss: 0.6783\n",
      "Epoch 9/34\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.6750 - loss: 0.6543\n",
      "Epoch 10/34\n",
      "1/1 - 0s - 32ms/step - accuracy: 0.6500 - loss: 0.6467\n",
      "Epoch 11/34\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.6500 - loss: 0.6422\n",
      "Epoch 12/34\n",
      "1/1 - 0s - 30ms/step - accuracy: 0.6250 - loss: 0.6370\n",
      "Epoch 13/34\n",
      "1/1 - 0s - 28ms/step - accuracy: 0.6625 - loss: 0.6332\n",
      "Epoch 14/34\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.6125 - loss: 0.6265\n",
      "Epoch 15/34\n",
      "1/1 - 0s - 35ms/step - accuracy: 0.6625 - loss: 0.6219\n",
      "Epoch 16/34\n",
      "1/1 - 0s - 31ms/step - accuracy: 0.6500 - loss: 0.6174\n",
      "Epoch 17/34\n",
      "1/1 - 0s - 29ms/step - accuracy: 0.6500 - loss: 0.6134\n",
      "Epoch 18/34\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.6500 - loss: 0.6073\n",
      "Epoch 19/34\n",
      "1/1 - 0s - 34ms/step - accuracy: 0.6875 - loss: 0.6025\n",
      "Epoch 20/34\n",
      "1/1 - 0s - 34ms/step - accuracy: 0.6500 - loss: 0.6013\n",
      "Epoch 21/34\n",
      "1/1 - 0s - 34ms/step - accuracy: 0.6875 - loss: 0.5944\n",
      "Epoch 22/34\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.6500 - loss: 0.6190\n",
      "Epoch 23/34\n",
      "1/1 - 0s - 32ms/step - accuracy: 0.6875 - loss: 0.5636\n",
      "Epoch 24/34\n",
      "1/1 - 0s - 31ms/step - accuracy: 0.6750 - loss: 0.5591\n",
      "Epoch 25/34\n",
      "1/1 - 0s - 29ms/step - accuracy: 0.7000 - loss: 0.5751\n",
      "Epoch 26/34\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.6750 - loss: 0.6314\n",
      "Epoch 27/34\n",
      "1/1 - 0s - 31ms/step - accuracy: 0.7250 - loss: 0.5483\n",
      "Epoch 28/34\n",
      "1/1 - 0s - 30ms/step - accuracy: 0.7125 - loss: 0.5255\n",
      "Epoch 29/34\n",
      "1/1 - 0s - 30ms/step - accuracy: 0.7375 - loss: 0.5120\n",
      "Epoch 30/34\n",
      "1/1 - 0s - 32ms/step - accuracy: 0.7375 - loss: 0.4984\n",
      "Epoch 31/34\n",
      "1/1 - 0s - 30ms/step - accuracy: 0.7500 - loss: 0.4872\n",
      "Epoch 32/34\n",
      "1/1 - 0s - 35ms/step - accuracy: 0.7750 - loss: 0.4786\n",
      "Epoch 33/34\n",
      "1/1 - 0s - 31ms/step - accuracy: 0.7625 - loss: 0.4695\n",
      "Epoch 34/34\n",
      "1/1 - 0s - 27ms/step - accuracy: 0.7750 - loss: 0.4649\n",
      "1/1 - 0s - 129ms/step\n",
      "Epoch 1/34\n",
      "Epoch 1/34\n",
      "Epoch 1/34\n",
      "Epoch 1/34\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m3.649    \u001b[0m | \u001b[0m80.67    \u001b[0m | \u001b[0m0.1997   \u001b[0m | \u001b[0m0.3057   \u001b[0m | \u001b[0m33.7     \u001b[0m | \u001b[0m1.186    \u001b[0m | \u001b[0m3.43     \u001b[0m | \u001b[0m1.682    \u001b[0m | \u001b[0m0.006599 \u001b[0m | \u001b[0m95.4     \u001b[0m | \u001b[0m0.9656   \u001b[0m | \u001b[0m5.659    \u001b[0m |\n",
      "Epoch 1/15\n",
      "5/5 - 1s - 196ms/step - accuracy: 0.4750 - loss: 1.6994\n",
      "Epoch 2/15\n",
      "5/5 - 0s - 9ms/step - accuracy: 0.5000 - loss: 0.8357\n",
      "Epoch 3/15\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.4375 - loss: 0.7512\n",
      "Epoch 4/15\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.5250 - loss: 0.6971\n",
      "Epoch 5/15\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.5500 - loss: 0.7185\n",
      "Epoch 6/15\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.4750 - loss: 0.8251\n",
      "Epoch 7/15\n",
      "5/5 - 0s - 9ms/step - accuracy: 0.5000 - loss: 0.7237\n",
      "Epoch 8/15\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.4750 - loss: 0.7278\n",
      "Epoch 9/15\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.5500 - loss: 0.7203\n",
      "Epoch 10/15\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.5500 - loss: 0.6868\n",
      "Epoch 11/15\n",
      "5/5 - 0s - 7ms/step - accuracy: 0.4500 - loss: 0.7364\n",
      "Epoch 12/15\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.5375 - loss: 0.7080\n",
      "Epoch 13/15\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.5500 - loss: 0.7118\n",
      "Epoch 14/15\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.4625 - loss: 0.7433\n",
      "Epoch 15/15\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.4125 - loss: 0.7279\n",
      "WARNING:tensorflow:5 out of the last 149 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002AF322BE0C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 150 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002AF322BE0C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - 77ms/step\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m2.437    \u001b[0m | \u001b[0m18.79    \u001b[0m | \u001b[0m0.6842   \u001b[0m | \u001b[0m0.2761   \u001b[0m | \u001b[0m14.88    \u001b[0m | \u001b[0m2.981    \u001b[0m | \u001b[0m1.138    \u001b[0m | \u001b[0m4.637    \u001b[0m | \u001b[0m0.02595  \u001b[0m | \u001b[0m69.63    \u001b[0m | \u001b[0m0.3117   \u001b[0m | \u001b[0m3.64     \u001b[0m |\n",
      "Epoch 1/48\n",
      "3/3 - 1s - 455ms/step - accuracy: 0.5625 - loss: 0.7379\n",
      "Epoch 2/48\n",
      "3/3 - 0s - 9ms/step - accuracy: 0.4375 - loss: 1.0559\n",
      "Epoch 3/48\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.4875 - loss: 0.7309\n",
      "Epoch 4/48\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.4500 - loss: 0.8307\n",
      "Epoch 5/48\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.5625 - loss: 0.6944\n",
      "Epoch 6/48\n",
      "3/3 - 0s - 10ms/step - accuracy: 0.4875 - loss: 0.6703\n",
      "Epoch 7/48\n",
      "3/3 - 0s - 9ms/step - accuracy: 0.4250 - loss: 0.7586\n",
      "Epoch 8/48\n",
      "3/3 - 0s - 8ms/step - accuracy: 0.4625 - loss: 0.7061\n",
      "Epoch 9/48\n",
      "3/3 - 0s - 9ms/step - accuracy: 0.6250 - loss: 0.6829\n",
      "Epoch 10/48\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.5750 - loss: 0.6868\n",
      "Epoch 11/48\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.4625 - loss: 0.7460\n",
      "Epoch 12/48\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.5250 - loss: 0.7252\n",
      "Epoch 13/48\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.4750 - loss: 0.7599\n",
      "Epoch 14/48\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.5250 - loss: 0.7094\n",
      "Epoch 15/48\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.4625 - loss: 0.7453\n",
      "Epoch 16/48\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.5250 - loss: 0.7012\n",
      "Epoch 17/48\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.5750 - loss: 0.6790\n",
      "Epoch 18/48\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.5625 - loss: 0.6916\n",
      "Epoch 19/48\n",
      "3/3 - 0s - 12ms/step - accuracy: 0.4625 - loss: 0.7588\n",
      "Epoch 20/48\n",
      "3/3 - 0s - 12ms/step - accuracy: 0.4625 - loss: 0.7504\n",
      "Epoch 21/48\n",
      "3/3 - 0s - 10ms/step - accuracy: 0.5500 - loss: 0.7212\n",
      "Epoch 22/48\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.5625 - loss: 0.6825\n",
      "Epoch 23/48\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.6250 - loss: 0.6945\n",
      "Epoch 24/48\n",
      "3/3 - 0s - 10ms/step - accuracy: 0.4875 - loss: 0.7489\n",
      "Epoch 25/48\n",
      "3/3 - 0s - 12ms/step - accuracy: 0.5250 - loss: 0.7093\n",
      "Epoch 26/48\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.5875 - loss: 0.6764\n",
      "Epoch 27/48\n",
      "3/3 - 0s - 12ms/step - accuracy: 0.6125 - loss: 0.6835\n",
      "Epoch 28/48\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.5500 - loss: 0.7227\n",
      "Epoch 29/48\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.5375 - loss: 0.6993\n",
      "Epoch 30/48\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.5000 - loss: 0.7450\n",
      "Epoch 31/48\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.5875 - loss: 0.6755\n",
      "Epoch 32/48\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.6000 - loss: 0.6832\n",
      "Epoch 33/48\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.5875 - loss: 0.6726\n",
      "Epoch 34/48\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.5375 - loss: 0.7021\n",
      "Epoch 35/48\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.6250 - loss: 0.6524\n",
      "Epoch 36/48\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.6125 - loss: 0.6575\n",
      "Epoch 37/48\n",
      "3/3 - 0s - 12ms/step - accuracy: 0.6500 - loss: 0.6746\n",
      "Epoch 38/48\n",
      "3/3 - 0s - 12ms/step - accuracy: 0.5625 - loss: 0.7272\n",
      "Epoch 39/48\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.5125 - loss: 0.7013\n",
      "Epoch 40/48\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.5125 - loss: 0.6925\n",
      "Epoch 41/48\n",
      "3/3 - 0s - 12ms/step - accuracy: 0.6125 - loss: 0.6532\n",
      "Epoch 42/48\n",
      "3/3 - 0s - 12ms/step - accuracy: 0.6250 - loss: 0.6895\n",
      "Epoch 43/48\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.6625 - loss: 0.6578\n",
      "Epoch 44/48\n",
      "3/3 - 0s - 9ms/step - accuracy: 0.5250 - loss: 0.7075\n",
      "Epoch 45/48\n",
      "3/3 - 0s - 10ms/step - accuracy: 0.6000 - loss: 0.6774\n",
      "Epoch 46/48\n",
      "3/3 - 0s - 12ms/step - accuracy: 0.5375 - loss: 0.6758\n",
      "Epoch 47/48\n",
      "3/3 - 0s - 10ms/step - accuracy: 0.6000 - loss: 0.6736\n",
      "Epoch 48/48\n",
      "3/3 - 0s - 9ms/step - accuracy: 0.6000 - loss: 0.6935\n",
      "1/1 - 0s - 119ms/step\n",
      "Epoch 1/48\n",
      "Epoch 1/48\n",
      "Epoch 1/48\n",
      "Epoch 1/48\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m4.374    \u001b[0m | \u001b[0m26.64    \u001b[0m | \u001b[0m0.9696   \u001b[0m | \u001b[0m0.4101   \u001b[0m | \u001b[0m47.58    \u001b[0m | \u001b[0m4.579    \u001b[0m | \u001b[0m3.392    \u001b[0m | \u001b[0m4.687    \u001b[0m | \u001b[0m0.00894  \u001b[0m | \u001b[0m27.64    \u001b[0m | \u001b[0m0.04523  \u001b[0m | \u001b[0m2.277    \u001b[0m |\n",
      "Epoch 1/21\n",
      "3/3 - 2s - 685ms/step - accuracy: 0.5125 - loss: 0.7228\n",
      "Epoch 2/21\n",
      "3/3 - 0s - 14ms/step - accuracy: 0.6125 - loss: 0.7206\n",
      "Epoch 3/21\n",
      "3/3 - 0s - 14ms/step - accuracy: 0.7000 - loss: 0.6406\n",
      "Epoch 4/21\n",
      "3/3 - 0s - 12ms/step - accuracy: 0.7500 - loss: 0.5825\n",
      "Epoch 5/21\n",
      "3/3 - 0s - 13ms/step - accuracy: 0.7750 - loss: 0.5623\n",
      "Epoch 6/21\n",
      "3/3 - 0s - 10ms/step - accuracy: 0.7125 - loss: 0.5730\n",
      "Epoch 7/21\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.7500 - loss: 0.5432\n",
      "Epoch 8/21\n",
      "3/3 - 0s - 12ms/step - accuracy: 0.7500 - loss: 0.5177\n",
      "Epoch 9/21\n",
      "3/3 - 0s - 10ms/step - accuracy: 0.7500 - loss: 0.5044\n",
      "Epoch 10/21\n",
      "3/3 - 0s - 12ms/step - accuracy: 0.7250 - loss: 0.5191\n",
      "Epoch 11/21\n",
      "3/3 - 0s - 9ms/step - accuracy: 0.7875 - loss: 0.4684\n",
      "Epoch 12/21\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.8250 - loss: 0.4182\n",
      "Epoch 13/21\n",
      "3/3 - 0s - 9ms/step - accuracy: 0.8125 - loss: 0.4303\n",
      "Epoch 14/21\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.7125 - loss: 0.5495\n",
      "Epoch 15/21\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.8375 - loss: 0.4143\n",
      "Epoch 16/21\n",
      "3/3 - 0s - 10ms/step - accuracy: 0.8375 - loss: 0.4225\n",
      "Epoch 17/21\n",
      "3/3 - 0s - 10ms/step - accuracy: 0.8500 - loss: 0.3930\n",
      "Epoch 18/21\n",
      "3/3 - 0s - 10ms/step - accuracy: 0.8750 - loss: 0.3549\n",
      "Epoch 19/21\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.9125 - loss: 0.2906\n",
      "Epoch 20/21\n",
      "3/3 - 0s - 9ms/step - accuracy: 0.8750 - loss: 0.3313\n",
      "Epoch 21/21\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.8625 - loss: 0.2967\n",
      "1/1 - 0s - 80ms/step\n",
      "Epoch 1/21\n",
      "Epoch 1/21\n",
      "Epoch 1/21\n",
      "Epoch 1/21\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m3.109    \u001b[0m | \u001b[0m34.42    \u001b[0m | \u001b[0m0.8287   \u001b[0m | \u001b[0m0.2427   \u001b[0m | \u001b[0m21.24    \u001b[0m | \u001b[0m3.171    \u001b[0m | \u001b[0m1.564    \u001b[0m | \u001b[0m4.209    \u001b[0m | \u001b[0m0.007548 \u001b[0m | \u001b[0m98.82    \u001b[0m | \u001b[0m0.7722   \u001b[0m | \u001b[0m1.391    \u001b[0m |\n",
      "Epoch 1/41\n",
      "1/1 - 1s - 570ms/step - accuracy: 0.5000 - loss: 0.6878\n",
      "Epoch 2/41\n",
      "1/1 - 0s - 21ms/step - accuracy: 0.5375 - loss: 0.6892\n",
      "Epoch 3/41\n",
      "1/1 - 0s - 21ms/step - accuracy: 0.5125 - loss: 0.6908\n",
      "Epoch 4/41\n",
      "1/1 - 0s - 21ms/step - accuracy: 0.5750 - loss: 0.6866\n",
      "Epoch 5/41\n",
      "1/1 - 0s - 23ms/step - accuracy: 0.5750 - loss: 0.6942\n",
      "Epoch 6/41\n",
      "1/1 - 0s - 29ms/step - accuracy: 0.5250 - loss: 0.6862\n",
      "Epoch 7/41\n",
      "1/1 - 0s - 27ms/step - accuracy: 0.5500 - loss: 0.6852\n",
      "Epoch 8/41\n",
      "1/1 - 0s - 22ms/step - accuracy: 0.5625 - loss: 0.6868\n",
      "Epoch 9/41\n",
      "1/1 - 0s - 20ms/step - accuracy: 0.5375 - loss: 0.6957\n",
      "Epoch 10/41\n",
      "1/1 - 0s - 24ms/step - accuracy: 0.5625 - loss: 0.6859\n",
      "Epoch 11/41\n",
      "1/1 - 0s - 24ms/step - accuracy: 0.5625 - loss: 0.6856\n",
      "Epoch 12/41\n",
      "1/1 - 0s - 28ms/step - accuracy: 0.5625 - loss: 0.6841\n",
      "Epoch 13/41\n",
      "1/1 - 0s - 27ms/step - accuracy: 0.5500 - loss: 0.6846\n",
      "Epoch 14/41\n",
      "1/1 - 0s - 26ms/step - accuracy: 0.5500 - loss: 0.6982\n",
      "Epoch 15/41\n",
      "1/1 - 0s - 22ms/step - accuracy: 0.5500 - loss: 0.6866\n",
      "Epoch 16/41\n",
      "1/1 - 0s - 31ms/step - accuracy: 0.5500 - loss: 0.6817\n",
      "Epoch 17/41\n",
      "1/1 - 0s - 29ms/step - accuracy: 0.5500 - loss: 0.6890\n",
      "Epoch 18/41\n",
      "1/1 - 0s - 27ms/step - accuracy: 0.5500 - loss: 0.6877\n",
      "Epoch 19/41\n",
      "1/1 - 0s - 30ms/step - accuracy: 0.5500 - loss: 0.6878\n",
      "Epoch 20/41\n",
      "1/1 - 0s - 25ms/step - accuracy: 0.5500 - loss: 0.6840\n",
      "Epoch 21/41\n",
      "1/1 - 0s - 30ms/step - accuracy: 0.5625 - loss: 0.6817\n",
      "Epoch 22/41\n",
      "1/1 - 0s - 30ms/step - accuracy: 0.5625 - loss: 0.6863\n",
      "Epoch 23/41\n",
      "1/1 - 0s - 25ms/step - accuracy: 0.5500 - loss: 0.6783\n",
      "Epoch 24/41\n",
      "1/1 - 0s - 28ms/step - accuracy: 0.5500 - loss: 0.6840\n",
      "Epoch 25/41\n",
      "1/1 - 0s - 29ms/step - accuracy: 0.5500 - loss: 0.6844\n",
      "Epoch 26/41\n",
      "1/1 - 0s - 25ms/step - accuracy: 0.5500 - loss: 0.6864\n",
      "Epoch 27/41\n",
      "1/1 - 0s - 26ms/step - accuracy: 0.5500 - loss: 0.6790\n",
      "Epoch 28/41\n",
      "1/1 - 0s - 29ms/step - accuracy: 0.5375 - loss: 0.6838\n",
      "Epoch 29/41\n",
      "1/1 - 0s - 22ms/step - accuracy: 0.5500 - loss: 0.6799\n",
      "Epoch 30/41\n",
      "1/1 - 0s - 24ms/step - accuracy: 0.5500 - loss: 0.6838\n",
      "Epoch 31/41\n",
      "1/1 - 0s - 28ms/step - accuracy: 0.5500 - loss: 0.6799\n",
      "Epoch 32/41\n",
      "1/1 - 0s - 22ms/step - accuracy: 0.5500 - loss: 0.6898\n",
      "Epoch 33/41\n",
      "1/1 - 0s - 26ms/step - accuracy: 0.5500 - loss: 0.6860\n",
      "Epoch 34/41\n",
      "1/1 - 0s - 28ms/step - accuracy: 0.5500 - loss: 0.6839\n",
      "Epoch 35/41\n",
      "1/1 - 0s - 23ms/step - accuracy: 0.5500 - loss: 0.6854\n",
      "Epoch 36/41\n",
      "1/1 - 0s - 22ms/step - accuracy: 0.5500 - loss: 0.6784\n",
      "Epoch 37/41\n",
      "1/1 - 0s - 27ms/step - accuracy: 0.5625 - loss: 0.6829\n",
      "Epoch 38/41\n",
      "1/1 - 0s - 21ms/step - accuracy: 0.5500 - loss: 0.6853\n",
      "Epoch 39/41\n",
      "1/1 - 0s - 26ms/step - accuracy: 0.5500 - loss: 0.6791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/41\n",
      "1/1 - 0s - 23ms/step - accuracy: 0.5500 - loss: 0.6772\n",
      "Epoch 41/41\n",
      "1/1 - 0s - 27ms/step - accuracy: 0.5625 - loss: 0.6790\n",
      "1/1 - 0s - 68ms/step\n",
      "Epoch 1/41\n",
      "Epoch 1/41\n",
      "Epoch 1/41\n",
      "Epoch 1/41\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m0.04418  \u001b[0m | \u001b[0m83.39    \u001b[0m | \u001b[0m0.7069   \u001b[0m | \u001b[0m0.3916   \u001b[0m | \u001b[0m40.85    \u001b[0m | \u001b[0m1.296    \u001b[0m | \u001b[0m2.434    \u001b[0m | \u001b[0m1.463    \u001b[0m | \u001b[0m0.08632  \u001b[0m | \u001b[0m66.1     \u001b[0m | \u001b[0m0.3309   \u001b[0m | \u001b[0m0.4449   \u001b[0m |\n",
      "Epoch 1/45\n",
      "3/3 - 2s - 520ms/step - accuracy: 0.4500 - loss: 1.1880\n",
      "Epoch 2/45\n",
      "3/3 - 0s - 13ms/step - accuracy: 0.4500 - loss: 1.0776\n",
      "Epoch 3/45\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.4500 - loss: 1.0216\n",
      "Epoch 4/45\n",
      "3/3 - 0s - 10ms/step - accuracy: 0.4500 - loss: 0.9713\n",
      "Epoch 5/45\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.4500 - loss: 0.8974\n",
      "Epoch 6/45\n",
      "3/3 - 0s - 9ms/step - accuracy: 0.4500 - loss: 0.8137\n",
      "Epoch 7/45\n",
      "3/3 - 0s - 9ms/step - accuracy: 0.4500 - loss: 0.7622\n",
      "Epoch 8/45\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.4500 - loss: 0.7471\n",
      "Epoch 9/45\n",
      "3/3 - 0s - 10ms/step - accuracy: 0.4500 - loss: 0.7229\n",
      "Epoch 10/45\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.4500 - loss: 0.7340\n",
      "Epoch 11/45\n",
      "3/3 - 0s - 12ms/step - accuracy: 0.4500 - loss: 0.7171\n",
      "Epoch 12/45\n",
      "3/3 - 0s - 12ms/step - accuracy: 0.4500 - loss: 0.7123\n",
      "Epoch 13/45\n",
      "3/3 - 0s - 9ms/step - accuracy: 0.4500 - loss: 0.7071\n",
      "Epoch 14/45\n",
      "3/3 - 0s - 9ms/step - accuracy: 0.5500 - loss: 0.6950\n",
      "Epoch 15/45\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.5125 - loss: 0.6970\n",
      "Epoch 16/45\n",
      "3/3 - 0s - 10ms/step - accuracy: 0.5375 - loss: 0.6921\n",
      "Epoch 17/45\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.5750 - loss: 0.6898\n",
      "Epoch 18/45\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.5500 - loss: 0.6895\n",
      "Epoch 19/45\n",
      "3/3 - 0s - 12ms/step - accuracy: 0.5125 - loss: 0.6900\n",
      "Epoch 20/45\n",
      "3/3 - 0s - 12ms/step - accuracy: 0.6125 - loss: 0.6845\n",
      "Epoch 21/45\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.5250 - loss: 0.6892\n",
      "Epoch 22/45\n",
      "3/3 - 0s - 10ms/step - accuracy: 0.5250 - loss: 0.6905\n",
      "Epoch 23/45\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.4125 - loss: 0.6986\n",
      "Epoch 24/45\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.6250 - loss: 0.6843\n",
      "Epoch 25/45\n",
      "3/3 - 0s - 9ms/step - accuracy: 0.5750 - loss: 0.6796\n",
      "Epoch 26/45\n",
      "3/3 - 0s - 12ms/step - accuracy: 0.6250 - loss: 0.6824\n",
      "Epoch 27/45\n",
      "3/3 - 0s - 10ms/step - accuracy: 0.4500 - loss: 0.6944\n",
      "Epoch 28/45\n",
      "3/3 - 0s - 10ms/step - accuracy: 0.5250 - loss: 0.6897\n",
      "Epoch 29/45\n",
      "3/3 - 0s - 9ms/step - accuracy: 0.5875 - loss: 0.6830\n",
      "Epoch 30/45\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.5375 - loss: 0.6803\n",
      "Epoch 31/45\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.5500 - loss: 0.6816\n",
      "Epoch 32/45\n",
      "3/3 - 0s - 12ms/step - accuracy: 0.5625 - loss: 0.6950\n",
      "Epoch 33/45\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.5375 - loss: 0.6921\n",
      "Epoch 34/45\n",
      "3/3 - 0s - 12ms/step - accuracy: 0.5625 - loss: 0.6846\n",
      "Epoch 35/45\n",
      "3/3 - 0s - 14ms/step - accuracy: 0.5500 - loss: 0.6813\n",
      "Epoch 36/45\n",
      "3/3 - 0s - 12ms/step - accuracy: 0.5500 - loss: 0.6818\n",
      "Epoch 37/45\n",
      "3/3 - 0s - 12ms/step - accuracy: 0.5375 - loss: 0.6909\n",
      "Epoch 38/45\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.5500 - loss: 0.6861\n",
      "Epoch 39/45\n",
      "3/3 - 0s - 13ms/step - accuracy: 0.5625 - loss: 0.6841\n",
      "Epoch 40/45\n",
      "3/3 - 0s - 12ms/step - accuracy: 0.5500 - loss: 0.6862\n",
      "Epoch 41/45\n",
      "3/3 - 0s - 10ms/step - accuracy: 0.5500 - loss: 0.6815\n",
      "Epoch 42/45\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.5500 - loss: 0.6832\n",
      "Epoch 43/45\n",
      "3/3 - 0s - 10ms/step - accuracy: 0.5750 - loss: 0.6863\n",
      "Epoch 44/45\n",
      "3/3 - 0s - 12ms/step - accuracy: 0.6125 - loss: 0.6845\n",
      "Epoch 45/45\n",
      "3/3 - 0s - 11ms/step - accuracy: 0.4875 - loss: 0.6988\n",
      "1/1 - 0s - 117ms/step\n",
      "Epoch 1/45\n",
      "Epoch 1/45\n",
      "Epoch 1/45\n",
      "Epoch 1/45\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m2.488    \u001b[0m | \u001b[0m39.27    \u001b[0m | \u001b[0m0.7296   \u001b[0m | \u001b[0m0.355    \u001b[0m | \u001b[0m45.49    \u001b[0m | \u001b[0m2.889    \u001b[0m | \u001b[0m1.478    \u001b[0m | \u001b[0m3.853    \u001b[0m | \u001b[0m0.0761   \u001b[0m | \u001b[0m60.51    \u001b[0m | \u001b[0m0.771    \u001b[0m | \u001b[0m3.457    \u001b[0m |\n",
      "Epoch 1/11\n",
      "2/2 - 2s - 774ms/step - accuracy: 0.4875 - loss: 0.9716\n",
      "Epoch 2/11\n",
      "2/2 - 0s - 13ms/step - accuracy: 0.6000 - loss: 3.7635\n",
      "Epoch 3/11\n",
      "2/2 - 0s - 14ms/step - accuracy: 0.5250 - loss: 2.5436\n",
      "Epoch 4/11\n",
      "2/2 - 0s - 14ms/step - accuracy: 0.5500 - loss: 2.3526\n",
      "Epoch 5/11\n",
      "2/2 - 0s - 15ms/step - accuracy: 0.4500 - loss: 1.4891\n",
      "Epoch 6/11\n",
      "2/2 - 0s - 14ms/step - accuracy: 0.5500 - loss: 1.0760\n",
      "Epoch 7/11\n",
      "2/2 - 0s - 14ms/step - accuracy: 0.4500 - loss: 1.0760\n",
      "Epoch 8/11\n",
      "2/2 - 0s - 14ms/step - accuracy: 0.5000 - loss: 0.8846\n",
      "Epoch 9/11\n",
      "2/2 - 0s - 13ms/step - accuracy: 0.5000 - loss: 0.8006\n",
      "Epoch 10/11\n",
      "2/2 - 0s - 15ms/step - accuracy: 0.4750 - loss: 0.7497\n",
      "Epoch 11/11\n",
      "2/2 - 0s - 13ms/step - accuracy: 0.5500 - loss: 0.7684\n",
      "1/1 - 0s - 70ms/step\n",
      "Epoch 1/11\n",
      "Epoch 1/11\n",
      "Epoch 1/11\n",
      "Epoch 1/11\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m4.182    \u001b[0m | \u001b[0m48.48    \u001b[0m | \u001b[0m0.02542  \u001b[0m | \u001b[0m0.1432   \u001b[0m | \u001b[0m11.26    \u001b[0m | \u001b[0m3.546    \u001b[0m | \u001b[0m2.257    \u001b[0m | \u001b[0m3.034    \u001b[0m | \u001b[0m0.09077  \u001b[0m | \u001b[0m32.44    \u001b[0m | \u001b[0m0.4104   \u001b[0m | \u001b[0m5.289    \u001b[0m |\n",
      "Epoch 1/47\n",
      "5/5 - 1s - 257ms/step - accuracy: 0.7000 - loss: 0.7594\n",
      "Epoch 2/47\n",
      "5/5 - 0s - 6ms/step - accuracy: 0.5875 - loss: 0.7299\n",
      "Epoch 3/47\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.5375 - loss: 0.7382\n",
      "Epoch 4/47\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.4625 - loss: 0.7726\n",
      "Epoch 5/47\n",
      "5/5 - 0s - 7ms/step - accuracy: 0.6625 - loss: 0.6916\n",
      "Epoch 6/47\n",
      "5/5 - 0s - 7ms/step - accuracy: 0.4750 - loss: 0.7134\n",
      "Epoch 7/47\n",
      "5/5 - 0s - 7ms/step - accuracy: 0.5500 - loss: 0.6908\n",
      "Epoch 8/47\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.5375 - loss: 0.6992\n",
      "Epoch 9/47\n",
      "5/5 - 0s - 7ms/step - accuracy: 0.5500 - loss: 0.6899\n",
      "Epoch 10/47\n",
      "5/5 - 0s - 7ms/step - accuracy: 0.4875 - loss: 0.7085\n",
      "Epoch 11/47\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.4000 - loss: 0.7322\n",
      "Epoch 12/47\n",
      "5/5 - 0s - 7ms/step - accuracy: 0.5375 - loss: 0.6975\n",
      "Epoch 13/47\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.5500 - loss: 0.6902\n",
      "Epoch 14/47\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.4875 - loss: 0.6930\n",
      "Epoch 15/47\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.5500 - loss: 0.6991\n",
      "Epoch 16/47\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.5500 - loss: 0.6904\n",
      "Epoch 17/47\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.5500 - loss: 0.7040\n",
      "Epoch 18/47\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.3500 - loss: 0.7082\n",
      "Epoch 19/47\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.5500 - loss: 0.7068\n",
      "Epoch 20/47\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.4375 - loss: 0.6985\n",
      "Epoch 21/47\n",
      "5/5 - 0s - 7ms/step - accuracy: 0.5500 - loss: 0.6891\n",
      "Epoch 22/47\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.5500 - loss: 0.6962\n",
      "Epoch 23/47\n",
      "5/5 - 0s - 9ms/step - accuracy: 0.5500 - loss: 0.6959\n",
      "Epoch 24/47\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.5500 - loss: 0.6883\n",
      "Epoch 25/47\n",
      "5/5 - 0s - 7ms/step - accuracy: 0.5500 - loss: 0.6896\n",
      "Epoch 26/47\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.5500 - loss: 0.6906\n",
      "Epoch 27/47\n",
      "5/5 - 0s - 7ms/step - accuracy: 0.5500 - loss: 0.6910\n",
      "Epoch 28/47\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.5500 - loss: 0.6902\n",
      "Epoch 29/47\n",
      "5/5 - 0s - 7ms/step - accuracy: 0.4875 - loss: 0.6978\n",
      "Epoch 30/47\n",
      "5/5 - 0s - 7ms/step - accuracy: 0.5500 - loss: 0.6919\n",
      "Epoch 31/47\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.5500 - loss: 0.6911\n",
      "Epoch 32/47\n",
      "5/5 - 0s - 7ms/step - accuracy: 0.5500 - loss: 0.6940\n",
      "Epoch 33/47\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.4625 - loss: 0.6930\n",
      "Epoch 34/47\n",
      "5/5 - 0s - 9ms/step - accuracy: 0.5500 - loss: 0.6920\n",
      "Epoch 35/47\n",
      "5/5 - 0s - 7ms/step - accuracy: 0.5500 - loss: 0.6970\n",
      "Epoch 36/47\n",
      "5/5 - 0s - 6ms/step - accuracy: 0.4500 - loss: 0.6965\n",
      "Epoch 37/47\n",
      "5/5 - 0s - 6ms/step - accuracy: 0.5500 - loss: 0.6893\n",
      "Epoch 38/47\n",
      "5/5 - 0s - 6ms/step - accuracy: 0.5500 - loss: 0.6921\n",
      "Epoch 39/47\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.5500 - loss: 0.6902\n",
      "Epoch 40/47\n",
      "5/5 - 0s - 7ms/step - accuracy: 0.5500 - loss: 0.6884\n",
      "Epoch 41/47\n",
      "5/5 - 0s - 7ms/step - accuracy: 0.5500 - loss: 0.6952\n",
      "Epoch 42/47\n",
      "5/5 - 0s - 7ms/step - accuracy: 0.5500 - loss: 0.6890\n",
      "Epoch 43/47\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.5500 - loss: 0.6905\n",
      "Epoch 44/47\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.5500 - loss: 0.6980\n",
      "Epoch 45/47\n",
      "5/5 - 0s - 10ms/step - accuracy: 0.5500 - loss: 0.6925\n",
      "Epoch 46/47\n",
      "5/5 - 0s - 8ms/step - accuracy: 0.5500 - loss: 0.6964\n",
      "Epoch 47/47\n",
      "5/5 - 0s - 6ms/step - accuracy: 0.5500 - loss: 0.6901\n",
      "2/2 - 0s - 88ms/step\n",
      "Epoch 1/47\n",
      "Epoch 1/47\n",
      "Epoch 1/47\n",
      "Epoch 1/47\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m1.83     \u001b[0m | \u001b[0m16.93    \u001b[0m | \u001b[0m0.2898   \u001b[0m | \u001b[0m0.1645   \u001b[0m | \u001b[0m47.19    \u001b[0m | \u001b[0m4.232    \u001b[0m | \u001b[0m3.534    \u001b[0m | \u001b[0m4.486    \u001b[0m | \u001b[0m0.08039  \u001b[0m | \u001b[0m26.79    \u001b[0m | \u001b[0m0.8926   \u001b[0m | \u001b[0m3.775    \u001b[0m |\n",
      "Epoch 1/19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 1s - 1s/step - accuracy: 0.5500 - loss: 0.6886\n",
      "Epoch 2/19\n",
      "1/1 - 0s - 21ms/step - accuracy: 0.4500 - loss: 0.7051\n",
      "Epoch 3/19\n",
      "1/1 - 0s - 30ms/step - accuracy: 0.5500 - loss: 0.6800\n",
      "Epoch 4/19\n",
      "1/1 - 0s - 27ms/step - accuracy: 0.6000 - loss: 0.6706\n",
      "Epoch 5/19\n",
      "1/1 - 0s - 28ms/step - accuracy: 0.6000 - loss: 0.6639\n",
      "Epoch 6/19\n",
      "1/1 - 0s - 26ms/step - accuracy: 0.5875 - loss: 0.6585\n",
      "Epoch 7/19\n",
      "1/1 - 0s - 24ms/step - accuracy: 0.6000 - loss: 0.6528\n",
      "Epoch 8/19\n",
      "1/1 - 0s - 24ms/step - accuracy: 0.6250 - loss: 0.6467\n",
      "Epoch 9/19\n",
      "1/1 - 0s - 28ms/step - accuracy: 0.6625 - loss: 0.6405\n",
      "Epoch 10/19\n",
      "1/1 - 0s - 22ms/step - accuracy: 0.6750 - loss: 0.6339\n",
      "Epoch 11/19\n",
      "1/1 - 0s - 27ms/step - accuracy: 0.6875 - loss: 0.6272\n",
      "Epoch 12/19\n",
      "1/1 - 0s - 30ms/step - accuracy: 0.7250 - loss: 0.6201\n",
      "Epoch 13/19\n",
      "1/1 - 0s - 30ms/step - accuracy: 0.7000 - loss: 0.6138\n",
      "Epoch 14/19\n",
      "1/1 - 0s - 30ms/step - accuracy: 0.7375 - loss: 0.6083\n",
      "Epoch 15/19\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.6750 - loss: 0.6068\n",
      "Epoch 16/19\n",
      "1/1 - 0s - 30ms/step - accuracy: 0.7500 - loss: 0.6086\n",
      "Epoch 17/19\n",
      "1/1 - 0s - 23ms/step - accuracy: 0.7000 - loss: 0.6007\n",
      "Epoch 18/19\n",
      "1/1 - 0s - 32ms/step - accuracy: 0.7500 - loss: 0.5926\n",
      "Epoch 19/19\n",
      "1/1 - 0s - 31ms/step - accuracy: 0.7375 - loss: 0.5855\n",
      "1/1 - 0s - 101ms/step\n",
      "Epoch 1/19\n",
      "Epoch 1/19\n",
      "Epoch 1/19\n",
      "Epoch 1/19\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m6.46     \u001b[0m | \u001b[0m90.65    \u001b[0m | \u001b[0m0.318    \u001b[0m | \u001b[0m0.144    \u001b[0m | \u001b[0m19.12    \u001b[0m | \u001b[0m2.708    \u001b[0m | \u001b[0m4.272    \u001b[0m | \u001b[0m4.443    \u001b[0m | \u001b[0m0.0007945\u001b[0m | \u001b[0m55.97    \u001b[0m | \u001b[0m0.4174   \u001b[0m | \u001b[0m1.555    \u001b[0m |\n",
      "Epoch 1/31\n",
      "2/2 - 1s - 582ms/step - accuracy: 0.4750 - loss: 9.3643\n",
      "Epoch 2/31\n",
      "2/2 - 0s - 17ms/step - accuracy: 0.5750 - loss: 1.5262\n",
      "Epoch 3/31\n",
      "2/2 - 0s - 14ms/step - accuracy: 0.4250 - loss: 0.7021\n",
      "Epoch 4/31\n",
      "2/2 - 0s - 17ms/step - accuracy: 0.5500 - loss: 0.7002\n",
      "Epoch 5/31\n",
      "2/2 - 0s - 13ms/step - accuracy: 0.5500 - loss: 0.6912\n",
      "Epoch 6/31\n",
      "2/2 - 0s - 13ms/step - accuracy: 0.5500 - loss: 0.6907\n",
      "Epoch 7/31\n",
      "2/2 - 0s - 18ms/step - accuracy: 0.5500 - loss: 0.6906\n",
      "Epoch 8/31\n",
      "2/2 - 0s - 13ms/step - accuracy: 0.5500 - loss: 0.6888\n",
      "Epoch 9/31\n",
      "2/2 - 0s - 13ms/step - accuracy: 0.5500 - loss: 0.6936\n",
      "Epoch 10/31\n",
      "2/2 - 0s - 13ms/step - accuracy: 0.5500 - loss: 0.6889\n",
      "Epoch 11/31\n",
      "2/2 - 0s - 14ms/step - accuracy: 0.5500 - loss: 0.6881\n",
      "Epoch 12/31\n",
      "2/2 - 0s - 13ms/step - accuracy: 0.5500 - loss: 0.6914\n",
      "Epoch 13/31\n",
      "2/2 - 0s - 15ms/step - accuracy: 0.5500 - loss: 0.6915\n",
      "Epoch 14/31\n",
      "2/2 - 0s - 10ms/step - accuracy: 0.5500 - loss: 0.6883\n",
      "Epoch 15/31\n",
      "2/2 - 0s - 17ms/step - accuracy: 0.5500 - loss: 0.7043\n",
      "Epoch 16/31\n",
      "2/2 - 0s - 16ms/step - accuracy: 0.5500 - loss: 0.6896\n",
      "Epoch 17/31\n",
      "2/2 - 0s - 14ms/step - accuracy: 0.5500 - loss: 0.6920\n",
      "Epoch 18/31\n",
      "2/2 - 0s - 14ms/step - accuracy: 0.5500 - loss: 0.6899\n",
      "Epoch 19/31\n",
      "2/2 - 0s - 12ms/step - accuracy: 0.5500 - loss: 0.6934\n",
      "Epoch 20/31\n",
      "2/2 - 0s - 16ms/step - accuracy: 0.5500 - loss: 0.6904\n",
      "Epoch 21/31\n",
      "2/2 - 0s - 14ms/step - accuracy: 0.5500 - loss: 0.6892\n",
      "Epoch 22/31\n",
      "2/2 - 0s - 13ms/step - accuracy: 0.4250 - loss: 0.7009\n",
      "Epoch 23/31\n",
      "2/2 - 0s - 15ms/step - accuracy: 0.5500 - loss: 0.6893\n",
      "Epoch 24/31\n",
      "2/2 - 0s - 17ms/step - accuracy: 0.5500 - loss: 0.6895\n",
      "Epoch 25/31\n",
      "2/2 - 0s - 14ms/step - accuracy: 0.5500 - loss: 0.6884\n",
      "Epoch 26/31\n",
      "2/2 - 0s - 15ms/step - accuracy: 0.5500 - loss: 0.6898\n",
      "Epoch 27/31\n",
      "2/2 - 0s - 11ms/step - accuracy: 0.4000 - loss: 0.7129\n",
      "Epoch 28/31\n",
      "2/2 - 0s - 13ms/step - accuracy: 0.5500 - loss: 0.6910\n",
      "Epoch 29/31\n",
      "2/2 - 0s - 14ms/step - accuracy: 0.5500 - loss: 0.6884\n",
      "Epoch 30/31\n",
      "2/2 - 0s - 12ms/step - accuracy: 0.5500 - loss: 0.6894\n",
      "Epoch 31/31\n",
      "2/2 - 0s - 13ms/step - accuracy: 0.5500 - loss: 0.6893\n",
      "1/1 - 0s - 76ms/step\n",
      "Epoch 1/31\n",
      "Epoch 1/31\n",
      "Epoch 1/31\n",
      "Epoch 1/31\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m0.9589   \u001b[0m | \u001b[0m40.39    \u001b[0m | \u001b[0m0.9429   \u001b[0m | \u001b[0m0.2293   \u001b[0m | \u001b[0m30.75    \u001b[0m | \u001b[0m3.812    \u001b[0m | \u001b[0m2.455    \u001b[0m | \u001b[0m4.887    \u001b[0m | \u001b[0m0.09625  \u001b[0m | \u001b[0m32.66    \u001b[0m | \u001b[0m0.4972   \u001b[0m | \u001b[0m2.106    \u001b[0m |\n",
      "Epoch 1/12\n",
      "7/7 - 1s - 195ms/step - accuracy: 0.5500 - loss: 13.6448\n",
      "Epoch 2/12\n",
      "7/7 - 0s - 7ms/step - accuracy: 0.4750 - loss: 0.8059\n",
      "Epoch 3/12\n",
      "7/7 - 0s - 6ms/step - accuracy: 0.5250 - loss: 0.6982\n",
      "Epoch 4/12\n",
      "7/7 - 0s - 6ms/step - accuracy: 0.4500 - loss: 0.7505\n",
      "Epoch 5/12\n",
      "7/7 - 0s - 5ms/step - accuracy: 0.5250 - loss: 0.7200\n",
      "Epoch 6/12\n",
      "7/7 - 0s - 5ms/step - accuracy: 0.5500 - loss: 0.6962\n",
      "Epoch 7/12\n",
      "7/7 - 0s - 6ms/step - accuracy: 0.5250 - loss: 0.7083\n",
      "Epoch 8/12\n",
      "7/7 - 0s - 6ms/step - accuracy: 0.5625 - loss: 0.6902\n",
      "Epoch 9/12\n",
      "7/7 - 0s - 5ms/step - accuracy: 0.4375 - loss: 0.7269\n",
      "Epoch 10/12\n",
      "7/7 - 0s - 6ms/step - accuracy: 0.5875 - loss: 0.7000\n",
      "Epoch 11/12\n",
      "7/7 - 0s - 6ms/step - accuracy: 0.5250 - loss: 0.7013\n",
      "Epoch 12/12\n",
      "7/7 - 0s - 5ms/step - accuracy: 0.4625 - loss: 0.6961\n",
      "2/2 - 0s - 75ms/step\n",
      "Epoch 1/12\n",
      "Epoch 1/12\n",
      "Epoch 1/12\n",
      "Epoch 1/12\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m2.279    \u001b[0m | \u001b[0m13.32    \u001b[0m | \u001b[0m0.6096   \u001b[0m | \u001b[0m0.3011   \u001b[0m | \u001b[0m12.06    \u001b[0m | \u001b[0m2.115    \u001b[0m | \u001b[0m4.633    \u001b[0m | \u001b[0m1.958    \u001b[0m | \u001b[0m0.01457  \u001b[0m | \u001b[0m54.05    \u001b[0m | \u001b[0m0.9857   \u001b[0m | \u001b[0m1.694    \u001b[0m |\n",
      "Epoch 1/25\n",
      "2/2 - 2s - 860ms/step - accuracy: 0.4625 - loss: 0.8337\n",
      "Epoch 2/25\n",
      "2/2 - 0s - 16ms/step - accuracy: 0.5375 - loss: 3.8501\n",
      "Epoch 3/25\n",
      "2/2 - 0s - 15ms/step - accuracy: 0.4250 - loss: 1.1356\n",
      "Epoch 4/25\n",
      "2/2 - 0s - 14ms/step - accuracy: 0.4500 - loss: 2.4228\n",
      "Epoch 5/25\n",
      "2/2 - 0s - 16ms/step - accuracy: 0.4500 - loss: 0.7911\n",
      "Epoch 6/25\n",
      "2/2 - 0s - 17ms/step - accuracy: 0.4500 - loss: 3.6718\n",
      "Epoch 7/25\n",
      "2/2 - 0s - 18ms/step - accuracy: 0.4625 - loss: 2.0973\n",
      "Epoch 8/25\n",
      "2/2 - 0s - 15ms/step - accuracy: 0.5625 - loss: 2.5161\n",
      "Epoch 9/25\n",
      "2/2 - 0s - 12ms/step - accuracy: 0.4500 - loss: 4.0896\n",
      "Epoch 10/25\n",
      "2/2 - 0s - 18ms/step - accuracy: 0.5500 - loss: 5.7758\n",
      "Epoch 11/25\n",
      "2/2 - 0s - 18ms/step - accuracy: 0.5625 - loss: 2.6685\n",
      "Epoch 12/25\n",
      "2/2 - 0s - 15ms/step - accuracy: 0.4500 - loss: 5.9929\n",
      "Epoch 13/25\n",
      "2/2 - 0s - 15ms/step - accuracy: 0.5500 - loss: 2.4770\n",
      "Epoch 14/25\n",
      "2/2 - 0s - 21ms/step - accuracy: 0.5500 - loss: 2.0057\n",
      "Epoch 15/25\n",
      "2/2 - 0s - 16ms/step - accuracy: 0.6375 - loss: 0.6862\n",
      "Epoch 16/25\n",
      "2/2 - 0s - 16ms/step - accuracy: 0.5750 - loss: 1.0272\n",
      "Epoch 17/25\n",
      "2/2 - 0s - 16ms/step - accuracy: 0.4500 - loss: 2.1893\n",
      "Epoch 18/25\n",
      "2/2 - 0s - 16ms/step - accuracy: 0.5500 - loss: 2.7142\n",
      "Epoch 19/25\n",
      "2/2 - 0s - 15ms/step - accuracy: 0.5750 - loss: 1.5722\n",
      "Epoch 20/25\n",
      "2/2 - 0s - 18ms/step - accuracy: 0.4625 - loss: 3.9025\n",
      "Epoch 21/25\n",
      "2/2 - 0s - 15ms/step - accuracy: 0.5500 - loss: 10.0014\n",
      "Epoch 22/25\n",
      "2/2 - 0s - 16ms/step - accuracy: 0.4375 - loss: 1.2830\n",
      "Epoch 23/25\n",
      "2/2 - 0s - 16ms/step - accuracy: 0.4500 - loss: 3.0344\n",
      "Epoch 24/25\n",
      "2/2 - 0s - 15ms/step - accuracy: 0.5500 - loss: 0.7354\n",
      "Epoch 25/25\n",
      "2/2 - 0s - 15ms/step - accuracy: 0.4500 - loss: 2.7378\n",
      "1/1 - 0s - 67ms/step\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m5.377    \u001b[0m | \u001b[0m78.55    \u001b[0m | \u001b[0m0.2376   \u001b[0m | \u001b[0m0.3913   \u001b[0m | \u001b[0m24.71    \u001b[0m | \u001b[0m3.529    \u001b[0m | \u001b[0m3.534    \u001b[0m | \u001b[0m3.143    \u001b[0m | \u001b[0m0.00912  \u001b[0m | \u001b[0m85.18    \u001b[0m | \u001b[0m0.3208   \u001b[0m | \u001b[0m1.306    \u001b[0m |\n",
      "Epoch 1/30\n",
      "2/2 - 2s - 940ms/step - accuracy: 0.4375 - loss: 4.0728\n",
      "Epoch 2/30\n",
      "2/2 - 0s - 17ms/step - accuracy: 0.5125 - loss: 0.6882\n",
      "Epoch 3/30\n",
      "2/2 - 0s - 16ms/step - accuracy: 0.5375 - loss: 0.8286\n",
      "Epoch 4/30\n",
      "2/2 - 0s - 15ms/step - accuracy: 0.5500 - loss: 0.7060\n",
      "Epoch 5/30\n",
      "2/2 - 0s - 14ms/step - accuracy: 0.5500 - loss: 0.7191\n",
      "Epoch 6/30\n",
      "2/2 - 0s - 16ms/step - accuracy: 0.5500 - loss: 0.7106\n",
      "Epoch 7/30\n",
      "2/2 - 0s - 17ms/step - accuracy: 0.5500 - loss: 0.6955\n",
      "Epoch 8/30\n",
      "2/2 - 0s - 18ms/step - accuracy: 0.5500 - loss: 0.6960\n",
      "Epoch 9/30\n",
      "2/2 - 0s - 16ms/step - accuracy: 0.5500 - loss: 0.6924\n",
      "Epoch 10/30\n",
      "2/2 - 0s - 15ms/step - accuracy: 0.5500 - loss: 0.6891\n",
      "Epoch 11/30\n",
      "2/2 - 0s - 15ms/step - accuracy: 0.5500 - loss: 0.6887\n",
      "Epoch 12/30\n",
      "2/2 - 0s - 21ms/step - accuracy: 0.5500 - loss: 0.6882\n",
      "Epoch 13/30\n",
      "2/2 - 0s - 17ms/step - accuracy: 0.5500 - loss: 0.6882\n",
      "Epoch 14/30\n",
      "2/2 - 0s - 15ms/step - accuracy: 0.5500 - loss: 0.6881\n",
      "Epoch 15/30\n",
      "2/2 - 0s - 15ms/step - accuracy: 0.5500 - loss: 0.6887\n",
      "Epoch 16/30\n",
      "2/2 - 0s - 15ms/step - accuracy: 0.5500 - loss: 0.6885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n",
      "2/2 - 0s - 14ms/step - accuracy: 0.5500 - loss: 0.6882\n",
      "Epoch 18/30\n",
      "2/2 - 0s - 15ms/step - accuracy: 0.5500 - loss: 0.6880\n",
      "Epoch 19/30\n",
      "2/2 - 0s - 17ms/step - accuracy: 0.5500 - loss: 0.6882\n",
      "Epoch 20/30\n",
      "2/2 - 0s - 17ms/step - accuracy: 0.5500 - loss: 0.6880\n",
      "Epoch 21/30\n",
      "2/2 - 0s - 15ms/step - accuracy: 0.5500 - loss: 0.6916\n",
      "Epoch 22/30\n",
      "2/2 - 0s - 15ms/step - accuracy: 0.5500 - loss: 0.6908\n",
      "Epoch 23/30\n",
      "2/2 - 0s - 15ms/step - accuracy: 0.5500 - loss: 0.6894\n",
      "Epoch 24/30\n",
      "2/2 - 0s - 15ms/step - accuracy: 0.5500 - loss: 0.6895\n",
      "Epoch 25/30\n",
      "2/2 - 0s - 14ms/step - accuracy: 0.5500 - loss: 0.6897\n",
      "Epoch 26/30\n",
      "2/2 - 0s - 14ms/step - accuracy: 0.5500 - loss: 0.6890\n",
      "Epoch 27/30\n",
      "2/2 - 0s - 18ms/step - accuracy: 0.5500 - loss: 0.6887\n",
      "Epoch 28/30\n",
      "2/2 - 0s - 17ms/step - accuracy: 0.5500 - loss: 0.6883\n",
      "Epoch 29/30\n",
      "2/2 - 0s - 14ms/step - accuracy: 0.5500 - loss: 0.6881\n",
      "Epoch 30/30\n",
      "2/2 - 0s - 14ms/step - accuracy: 0.5500 - loss: 0.6888\n",
      "1/1 - 0s - 100ms/step\n",
      "Epoch 1/30\n",
      "Epoch 1/30\n",
      "Epoch 1/30\n",
      "Epoch 1/30\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0mnan      \u001b[0m | \u001b[0m0.3262   \u001b[0m | \u001b[0m63.18    \u001b[0m | \u001b[0m0.6776   \u001b[0m | \u001b[0m0.1066   \u001b[0m | \u001b[0m30.48    \u001b[0m | \u001b[0m1.906    \u001b[0m | \u001b[0m3.581    \u001b[0m | \u001b[0m1.697    \u001b[0m | \u001b[0m0.06912  \u001b[0m | \u001b[0m44.81    \u001b[0m | \u001b[0m0.9367   \u001b[0m | \u001b[0m0.9626   \u001b[0m |\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda2\\Lib\\site-packages\\bayes_opt\\bayesian_optimization.py:305\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[1;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 305\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue)\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda2\\Lib\\site-packages\\bayes_opt\\bayesian_optimization.py:27\u001b[0m, in \u001b[0;36mQueue.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueue is empty, no more objects to retrieve.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mStopIteration\u001b[0m: Queue is empty, no more objects to retrieve.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 70\u001b[0m\n\u001b[0;32m     68\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     69\u001b[0m nn_opt \u001b[38;5;241m=\u001b[39m BayesianOptimization(f\u001b[38;5;241m=\u001b[39mbay_area, pbounds\u001b[38;5;241m=\u001b[39mparams, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 70\u001b[0m nn_opt\u001b[38;5;241m.\u001b[39mmaximize(init_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSearch took \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m minutes\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m ((time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda2\\Lib\\site-packages\\bayes_opt\\bayesian_optimization.py:308\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[1;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    307\u001b[0m     util\u001b[38;5;241m.\u001b[39mupdate_params()\n\u001b[1;32m--> 308\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuggest(util)\n\u001b[0;32m    309\u001b[0m     iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobe(x_probe, lazy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda2\\Lib\\site-packages\\bayes_opt\\bayesian_optimization.py:220\u001b[0m, in \u001b[0;36mBayesianOptimization.suggest\u001b[1;34m(self, utility_function)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m    219\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gp\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39mparams, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39mtarget)\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_constrained:\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstraint\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39mparams,\n\u001b[0;32m    223\u001b[0m                             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39m_constraint_values)\n",
      "File \u001b[1;32m~\\anaconda2\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:237\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    236\u001b[0m     dtype, ensure_2d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 237\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    238\u001b[0m     X,\n\u001b[0;32m    239\u001b[0m     y,\n\u001b[0;32m    240\u001b[0m     multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    241\u001b[0m     y_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    242\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m    243\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    244\u001b[0m )\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# Normalize target value\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_y:\n",
      "File \u001b[1;32m~\\anaconda2\\Lib\\site-packages\\sklearn\\base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda2\\Lib\\site-packages\\sklearn\\utils\\validation.py:1122\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[0;32m   1106\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[1;32m-> 1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32m~\\anaconda2\\Lib\\site-packages\\sklearn\\utils\\validation.py:1132\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_output:\n\u001b[1;32m-> 1132\u001b[0m     y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1133\u001b[0m         y,\n\u001b[0;32m   1134\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1135\u001b[0m         force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1136\u001b[0m         ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1137\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1138\u001b[0m         input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1139\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1140\u001b[0m     )\n\u001b[0;32m   1141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1142\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n",
      "File \u001b[1;32m~\\anaconda2\\Lib\\site-packages\\sklearn\\utils\\validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m         )\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 921\u001b[0m         _assert_all_finite(\n\u001b[0;32m    922\u001b[0m             array,\n\u001b[0;32m    923\u001b[0m             input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    924\u001b[0m             estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    925\u001b[0m             allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    926\u001b[0m         )\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\anaconda2\\Lib\\site-packages\\sklearn\\utils\\validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "X_train = np.random.rand(100, 10, 1)  \n",
    "y_train = np.random.randint(0, 2, 100) \n",
    "timesteps = X_train.shape[1]\n",
    "input_dim = X_train.shape[2]\n",
    "n_classes = 2\n",
    "\n",
    "#scoring function\n",
    "score_accuracy = make_scorer(accuracy_score)\n",
    "\n",
    "def bay_area(neurons, activation, kernel, optimizer, learning_rate, batch_size, epochs,\n",
    "              layers1, layers2, normalization, dropout, dropout_rate): \n",
    "    optimizerL = ['SGD', 'Adam', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl', 'SGD']\n",
    "    optimizerD= {'Adam':Adam(learning_rate=learning_rate), 'SGD':SGD(learning_rate=learning_rate),\n",
    "                 'RMSprop':RMSprop(learning_rate=learning_rate), 'Adadelta':Adadelta(learning_rate=learning_rate),\n",
    "                 'Adagrad':Adagrad(learning_rate=learning_rate), 'Adamax':Adamax(learning_rate=learning_rate),\n",
    "                 'Nadam':Nadam(learning_rate=learning_rate), 'Ftrl':Ftrl(learning_rate=learning_rate)}\n",
    "    activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu',\n",
    "                   'elu', 'exponential', LeakyReLU, 'relu']\n",
    "    \n",
    "    neurons = round(neurons)\n",
    "    kernel = round(kernel)\n",
    "    activation = activationL[round(activation)]\n",
    "    optimizer = optimizerD[optimizerL[round(optimizer)]]\n",
    "    batch_size = round(batch_size)\n",
    "    epochs = round(epochs)\n",
    "    layers1 = round(layers1)\n",
    "    layers2 = round(layers2)\n",
    "    \n",
    "    def cnn_model():\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(neurons, kernel_size=kernel, activation=activation, input_shape=(timesteps, input_dim)))\n",
    "        if normalization > 0.5:\n",
    "            model.add(BatchNormalization())\n",
    "        for i in range(layers1):\n",
    "            model.add(Dense(neurons, activation=activation))\n",
    "        if dropout > 0.5:\n",
    "            model.add(Dropout(dropout_rate, seed=123))\n",
    "        for i in range(layers2):\n",
    "            model.add(Dense(neurons, activation=activation))\n",
    "        model.add(MaxPooling1D())\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(n_classes, activation='softmax'))\n",
    "        model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    es = EarlyStopping(monitor='accuracy', mode='max', verbose=2, patience=20)\n",
    "    nn = KerasClassifier(build_fn=cnn_model, epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "    score = cross_val_score(nn, X_train, y_train, scoring=score_accuracy, cv=kfold, fit_params={'callbacks': [es]}).mean()\n",
    "    return score\n",
    "\n",
    "# Define the parameter bounds for Bayesian Optimization\n",
    "params = {\n",
    "    'neurons': (10, 100),\n",
    "    'activation': (0, 8),\n",
    "    'kernel': (1, 5),\n",
    "    'optimizer': (0, 7),\n",
    "    'learning_rate': (0.0001, 0.1),\n",
    "    'batch_size': (10, 100),\n",
    "    'epochs': (10, 50),\n",
    "    'layers1': (1, 5),\n",
    "    'layers2': (1, 5),\n",
    "    'normalization': (0, 1),\n",
    "    'dropout': (0, 1),\n",
    "    'dropout_rate': (0.1, 0.5)\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "nn_opt = BayesianOptimization(f=bay_area, pbounds=params, random_state=42)\n",
    "nn_opt.maximize(init_points=15, n_iter=4)\n",
    "print('Search took %s minutes' % ((time.time() - start) / 60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ab0bb166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'softsign',\n",
       " 'batch_size': 96,\n",
       " 'dropout': 0.7319939418114051,\n",
       " 'dropout_rate': 0.3394633936788146,\n",
       " 'epochs': 16,\n",
       " 'kernel': 2,\n",
       " 'layers1': 1,\n",
       " 'layers2': 4,\n",
       " 'learning_rate': 0.060151389673146566,\n",
       " 'neurons': 74,\n",
       " 'normalization': 0.020584494295802447,\n",
       " 'optimizer': <keras.src.optimizers.ftrl.Ftrl at 0x2af3476f190>}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimum = nn_opt.max['params']\n",
    "learning_rate = optimum['learning_rate']\n",
    "activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu',\n",
    "               'elu', 'exponential', LeakyReLU,'relu']\n",
    "optimum['activation'] = activationL[round(optimum['activation'])]\n",
    "optimum['batch_size'] = round(optimum['batch_size'])\n",
    "optimum['epochs'] = round(optimum['epochs'])\n",
    "optimum['layers1'] = round(optimum['layers1'])\n",
    "optimum['layers2'] = round(optimum['layers2'])\n",
    "optimum['neurons'] = round(optimum['neurons'])\n",
    "optimizerL = ['Adam', 'SGD', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl','Adam']\n",
    "optimizerD= {'Adam':Adam(learning_rate=learning_rate), 'SGD':SGD(learning_rate=learning_rate),\n",
    "             'RMSprop':RMSprop(learning_rate=learning_rate), 'Adadelta':Adadelta(learning_rate=learning_rate),\n",
    "             'Adagrad':Adagrad(learning_rate=learning_rate), 'Adamax':Adamax(learning_rate=learning_rate),\n",
    "             'Nadam':Nadam(learning_rate=learning_rate), 'Ftrl':Ftrl(learning_rate=learning_rate)}\n",
    "optimum['optimizer'] = optimizerD[optimizerL[round(optimum['optimizer'])]]\n",
    "optimum['kernel'] = round(optimum['kernel'])\n",
    "optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "97744b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Need to add learning rate to the optimizer type??\n",
    "epochs = optimum[\"epochs\"]\n",
    "batch_size = optimum[\"batch_size\"]\n",
    "#n_hidden = 32\n",
    "\n",
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = 15 #_count_classes(Y_train)\n",
    "layers1 = optimum[\"layers1\"]\n",
    "layers2 = optimum[\"layers2\"]\n",
    "activation = optimum[\"activation\"]\n",
    "kernel = optimum[\"kernel\"]\n",
    "neurons = optimum[\"neurons\"]\n",
    "normalization = optimum[\"normalization\"]\n",
    "dropout = optimum[\"dropout\"]\n",
    "dropout_rate = optimum[\"dropout_rate\"]\n",
    "optimizer = optimum[\"optimizer\"]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(neurons, kernel_size=kernel, activation=activation, input_shape=(timesteps, input_dim)))\n",
    "if normalization > 0.5:\n",
    "    model.add(BatchNormalization())\n",
    "for i in range(layers1):\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "if dropout > 0.5:\n",
    "    model.add(Dropout(dropout_rate, seed=123))\n",
    "for i in range(layers2):\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(n_classes, activation='softmax')) #softmax sigmoid\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']) #binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4b3b9e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.09      0.16      2955\n",
      "           1       0.18      0.61      0.28       879\n",
      "           2       0.00      0.00      0.00       162\n",
      "           3       0.00      0.00      0.00        64\n",
      "           4       0.00      0.00      0.00        25\n",
      "           5       0.00      0.00      0.00        67\n",
      "           6       0.00      0.00      0.00         9\n",
      "           7       0.00      0.00      0.00        46\n",
      "           8       0.00      0.14      0.00         7\n",
      "           9       0.09      0.04      0.06       360\n",
      "          10       0.00      0.00      0.00         8\n",
      "          11       0.00      0.00      0.00         4\n",
      "          13       0.00      0.00      0.00         3\n",
      "          14       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.18      4590\n",
      "   macro avg       0.08      0.06      0.04      4590\n",
      "weighted avg       0.58      0.18      0.16      4590\n",
      "\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(report)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Plot the confusion matrix\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test, y_pred)\n\u001b[0;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m7\u001b[39m))\n\u001b[0;32m     12\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(cm, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlues\u001b[39m\u001b[38;5;124m'\u001b[39m, xticklabels\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y), yticklabels\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y))\n",
      "Cell \u001b[1;32mIn[69], line 3\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(Y_true, Y_pred)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfusion_matrix\u001b[39m(Y_true, Y_pred):\n\u001b[1;32m----> 3\u001b[0m     Y_true \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries([activities[y] \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39margmax(Y_true, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)])\n\u001b[0;32m      4\u001b[0m     Y_pred \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries([activities[y] \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39margmax(Y_pred, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)])\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mcrosstab(Y_true, Y_pred, rownames\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m'\u001b[39m], colnames\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPred\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda2\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:1229\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1142\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m-> 1229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124margmax\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\anaconda2\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3608a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
